{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanraj/opt/anaconda3/lib/python3.7/site-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/rohanraj/opt/anaconda3/lib/python3.7/site-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/Users/rohanraj/opt/anaconda3/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Users/rohanraj/opt/anaconda3/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "/Users/rohanraj/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "/Users/rohanraj/opt/anaconda3/lib/python3.7/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/kernels/scriptcontent/11511967/notebook\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import ast\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.mlab as mlab\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "# from textblob import TextBlob\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import tnt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import indian\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.summarization import summarize\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import stanfordnlp\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from bokeh.plotting import figure, output_file, show\n",
    "# from bokeh.models import Label\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/rohanraj/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_tokenizer.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/rohanraj/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_tagger.pt', 'pretrain_path': '/Users/rohanraj/stanfordnlp_resources/hi_hdtb_models/hi_hdtb.pretrain.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/rohanraj/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_lemmatizer.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/rohanraj/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_parser.pt', 'pretrain_path': '/Users/rohanraj/stanfordnlp_resources/hi_hdtb_models/hi_hdtb.pretrain.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline ( lang = 'hi' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = '../data/hindi.txt'\n",
    "with open(datafile,'r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.split(\"॥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1290/1290 [00:00<00:00, 407981.61it/s]\n"
     ]
    }
   ],
   "source": [
    "text_sentence = []\n",
    "i = 0\n",
    "for word in tqdm(text):\n",
    "#     print(i,word)\n",
    "    if re.findall(\"^\\s?\\d+\\s?\",word):\n",
    "        continue\n",
    "    else:   \n",
    "        text_sentence.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' वानर हनुमान सीमा के देखने की उत्कण्ठा येसूयास्त की प्रतीक्षा करता भया ',\n",
       " ' घ४-९) सीता को रावण के भन्तापुर में ढूंढना : वह महावीर्य महान हृदय पाछा वानर श्रेष्ठ रात के समय अद्वार से कोट को फांद कर का में प्रविष्ट हृया ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentence[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_sentence) #total sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hindi stopwords\n",
    "stop_words_df = pd.read_csv(\"../data/stopwords.txt\", header = None)\n",
    "stop_words = list(set(stop_words_df.values.reshape(1,-1).tolist()[0]))\n",
    "stop_words.extend([\"।\", \"।।\", \")\", \"(\", \",\",'\"',\"हे\", \"हो\", 'में','से','COMMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['दीजिए', 'तक']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_str_from_list(original_read_text):\n",
    "    prepared_text = \"\"\n",
    "    for line in original_read_text:\n",
    "        line = line.split()\n",
    "#       print(line)\n",
    "        tmp_line = \" \".join(line)\n",
    "        prepared_text += \" \\n\"+tmp_line\n",
    "    return prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_text = create_str_from_list(text_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nवानर हनुमान सीमा के देखने की उत्कण्ठा येसूयास्त की प्रतीक्षा करता भया \\nघ४-९) सीता को रावण के भन्तापुर में ढूंढना : वह महावीर्य महान हृदय पाछा वानर श्रेष्ठ रात के समय अद्वार से कोट को फांद कर का में प्रविष्ट हृया \\nधानरराज के उस हितैषी ने लंका नगरी में प्रवेश करके मानों अपना बायां पाओं शत्रु के सिर पर रख दिया \\nउस समय सुन्दर \\'सब ओर से सजे हुए श्वेत मेघ के तुल्य राक्षसों के जो पद्माकार, स्वस्तिकाकार, और वर्धमान घर है, उन से इंका जगमन. कर रही थी, राधा के अर्थ वह श्रीमान् घूमता हुमा उसे देखता भया और आनन्दित होता भया ।। ३, ४ \\nएक भवन से दूसरे भवन को जाते हुए उस वानरश्रेष्ठ ने वहाँ र विविध भाकृति और रूपों वाले भवन देखे \\nवहाँ राक्षसों के घरों में उसने अप \"करते हुओं के मन्त्र मुने और स्वाध्याय में रत राक्षसों को देखा \\nराक्षसों के घर से घर और बगीचों को देखता हुआ बेधड़क यह महलों के पास घूमा \\nतव पवनपुत्र हनुमान ने यह भवन श्रेष्ठ देखा, जो राक्षसपति का भवन है, और बहुत महलों से भरपूर है \\nविशाल नेत्रोंवाली वैदेही सीता को ढूंढता हुआ शत्रुनों के मारनेवाला, हनुमान उसके चारों ओर घूमा ।। ९ \\nतब वह उस सुन्दर पड़ी माला की ओर मस्थित हुआ, जो उत्तम स्त्री की तरह रावण की बड़ी पारी थी \\nजिमकी सीदियों में माणेयां जड़ी हुई हैं, जो सोने के झरोकों से भूपित हैं, सङ्गमर्मर का फर्श है, और बीच २ में दान्त का काम किया हुआ है \\nजो सम, सीधे, बड़े कंचे पूरे २ मजे हुए स्तम्भों मे मानों आते ऊँचे पलों से छौ की ओर प्रस्थित हुई है \\nसोंचम गलीचा जिसमें पिछा हुआ है, राक्षों के अधिपति से सेवित है, मन को प्रसन्न करने वाली और शरीर की कान्ति को बढ़ाने वाली है।। १३ \\nदीपकों के प्रकाश से, रावण के तेज से, और भूषणों की चमक मे, पानों जलती हुई प्रतीत होती है। \\nउस शाला में देखते हुए इनुमान् ने रत्नों मे भाषेत एक दिव्य विलोरी शपनानन ( बैठने मोने का एला ) देखा \\nओर शराब पीकर बन्द हुए, श्रीद चमकते हुए पलङ्ग -. पर लेटे हुए राक्षसाधिपति को उस महारानर ने देखा \\nससके पास आकर बड़ा गीवन इा अत्यन्त डरे हुए की तरह पीछे-इट गया, और प्यारी खियों वाले उस राक्षसपति के घर. में बस वानर यूयपति ने चन्द्र तुल्य मुखवाली, सुन्दर कुण्डल पहने हुई, ताजे घुषषों की पालाएं और भूषणोंवाली पनियों को देसा \\nउन में से एकान्त स्थिव एक गुभ शय्या के ऊपर लेटी हुई रुपवती उम ने एक खो देखी \\nजो अपनी शोभा से मानों उस उत्तम भवन को शोभायमान करती थी, बद्द मन्दोदरी थी, जोकि सुन्दर रूपवती वहां लेटी हुई थी \\nमहाबाहु पवनसुत ने उस भूषित स्त्री को देखकर उमके रूप यौवन की सम्पदा से रूपाल किया, कि कदाचित यह सीता हो \\nय०१०-११) राधण के अन्तःपुर में सीता का न पाना पर उसी समय उस रूपाळ को पटाकर, स्थित हुा महा . घानर सीता के विषय भरा विचार करता भया \\nकि राम से वियुक्त हुई वह मुन्दरीन सो सक्ती है, न भोग रती है, न अलङ्कार कर सक्ती है, न पान सेवन कर सक्ती है \\nनि:सन्देह यह कोई और है, ऐसा'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"घ४-९) सीता को रावण के भन्तापुर में ढूंढना : वह महावीर्य महान हृदय पाछा वानर श्रेष्ठ रात के समय अद्वार से कोट को फांद कर का में प्रविष्ट हृया \\nउस समय सुन्दर 'सब ओर से सजे हुए श्वेत मेघ के तुल्य राक्षसों के जो पद्माकार, स्वस्तिकाकार, और वर्धमान घर है, उन से इंका जगमन.\\nराक्षसों के घर से घर और बगीचों को देखता हुआ बेधड़क यह महलों के पास घूमा \\nतब वह उस सुन्दर पड़ी माला की ओर मस्थित हुआ, जो उत्तम स्त्री की तरह रावण की बड़ी पारी थी \\nमें बस वानर यूयपति ने चन्द्र तुल्य मुखवाली, सुन्दर कुण्डल पहने हुई, ताजे घुषषों की पालाएं और भूषणोंवाली पनियों को देसा \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(str_text[0:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68718"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization(str_text):\n",
    "    startflag = 0\n",
    "    endflag = 2500\n",
    "    parsed_text = {'text':[], 'title':[]}\n",
    "    for summary in range(int(len(str_text)/endflag)):\n",
    "        summarization_block = summarize(str_text[startflag:endflag])\n",
    "        parsed_text['text'].append(str_text[startflag:endflag])\n",
    "        parsed_text['title'].append(summarization_block)\n",
    "        startflag +=2500\n",
    "        endflag +=2500\n",
    "    return pd.DataFrame(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = summarization(str_text)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('input_abstarct_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Summarization from Gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrankTfIdf(document):\n",
    "    # sentence_tokenizer = PunktSentenceTokenizer()\n",
    "    # sentences = sentence_tokenizer.tokenize(document, 'hindi')\n",
    "\n",
    "    sentences = document\n",
    "    bow_matrix = CountVectorizer().fit_transform(sentences)\n",
    "    # normalized = TfidfTransformer(norm='l2', use_idf=True, use_bm25idf=True, smooth_idf=True,\n",
    "    #              delta_idf=False, sublinear_tf=False, bm25_tf=True).fit_transform(bow_matrix)\n",
    "\n",
    "    normalized = TfidfTransformer().fit_transform(bow_matrix)\n",
    "    similarity_graph = normalized * normalized.T\n",
    "\n",
    "    nx_graph = nx.from_scipy_sparse_matrix(similarity_graph)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    return sorted(((scores[i], s) for i, s in enumerate(sentences)),\n",
    "                  reverse=True)\n",
    "def orderSentences(rankedList, data, initSentences):\n",
    "    index = ['']*len(data)\n",
    "    # print(rankedList)\n",
    "    for eachRanked in rankedList[0:int(math.ceil(0.2*len(rankedList)))]:\n",
    "        sen = eachRanked[1]\n",
    "        index[data.index(sen)] = initSentences[data.index(sen)]\n",
    "        # print(data.index(sen))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(text_sentence)/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_summarization(text_sentence):\n",
    "    startflag = 0\n",
    "    endflag = 25\n",
    "    parsed_text = {'text':[], 'alt_title':[]}\n",
    "    sentence =''\n",
    "    for summary in range(int(len(text_sentence)/endflag)):\n",
    "        rankedSentences = textrankTfIdf(text_sentence[startflag:endflag])\n",
    "        orderedsentences = orderSentences(rankedSentences, text_sentence[startflag:endflag], text_sentence[startflag:endflag])\n",
    "        for ordered in orderedsentences:\n",
    "            if ordered != \"\":\n",
    "                sentence += ordered \n",
    "        parsed_text['alt_title'].append(sentence)\n",
    "        parsed_text['text'].append(text_sentence[startflag:endflag])\n",
    "        startflag +=25\n",
    "        endflag +=25\n",
    "        sentence =''\n",
    "    return pd.DataFrame(parsed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = alternate_summarization(text_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>alt_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ वानर हनुमान सीमा के देखने की उत्कण्ठा येसूया...</td>\n",
       "      <td>उस समय सुन्दर 'सब ओर से सजे हुए श्वेत मेघ के ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ मेरी दृष्टि आजतक (ऐमी अवस्था में ) परस्त्रिय...</td>\n",
       "      <td>सो मैंने शुद्ध मन से रावण का पारा अन्तःपुर ढू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ तब उस वानर ने सारे जगह में सुहावना एक पर्वत ...</td>\n",
       "      <td>तब उस वानर ने सारे जगह में सुहावना एक पर्वत द...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ , १८) प्रभात का समय और रावण का अशोकवनिका में...</td>\n",
       "      <td>उस समय मङ्गक बाओं और कानों के प्यारे शब्दों स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ पह तेरा सुन्दर बना हुथा, यौवन चला जारहा है, ...</td>\n",
       "      <td>सारे लोकों से पल से हर कर जो मैं रत्न लाचा हू...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [ वानर हनुमान सीमा के देखने की उत्कण्ठा येसूया...   \n",
       "1  [ मेरी दृष्टि आजतक (ऐमी अवस्था में ) परस्त्रिय...   \n",
       "2  [ तब उस वानर ने सारे जगह में सुहावना एक पर्वत ...   \n",
       "3  [ , १८) प्रभात का समय और रावण का अशोकवनिका में...   \n",
       "4  [ पह तेरा सुन्दर बना हुथा, यौवन चला जारहा है, ...   \n",
       "\n",
       "                                           alt_title  \n",
       "0   उस समय सुन्दर 'सब ओर से सजे हुए श्वेत मेघ के ...  \n",
       "1   सो मैंने शुद्ध मन से रावण का पारा अन्तःपुर ढू...  \n",
       "2   तब उस वानर ने सारे जगह में सुहावना एक पर्वत द...  \n",
       "3   उस समय मङ्गक बाओं और कानों के प्यारे शब्दों स...  \n",
       "4   सारे लोकों से पल से हर कर जो मैं रत्न लाचा हू...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>alt_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ वानर हनुमान सीमा के देखने की उत्कण्ठा येसूया...</td>\n",
       "      <td>उस समय सुन्दर 'सब ओर से सजे हुए श्वेत मेघ के ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [ वानर हनुमान सीमा के देखने की उत्कण्ठा येसूया...   \n",
       "\n",
       "                                           alt_title  \n",
       "0   उस समय सुन्दर 'सब ओर से सजे हुए श्वेत मेघ के ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[['text','alt_title']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv('summary_alt_gensim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv('../data/summary_alt_gensim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner(sentence_ner,row_no):\n",
    "    parsed_text = {'sentence':[], 'word':[], 'ner':[]}\n",
    "    words = re.findall(\"([^<]+)<[^>]+>\",sentence_ner)\n",
    "    tags = re.findall(\"<([^>]+)>\",sentence_ner)\n",
    "    \n",
    "    # for word in words: append word #we need to write seperate tags\n",
    "    for index in range(len(words)):\n",
    "        parsed_text['word'].append(words[index])\n",
    "        parsed_text['ner'].append(tags[index])\n",
    "        parsed_text['sentence'].append(row_no)\n",
    "    \n",
    "    return pd.DataFrame(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-04 21:23:43,200 loading file /Users/rohanraj/Documents/Master/CaseStudy2/code/resources/taggers/netag/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "# load the model you trained\n",
    "model = SequenceTagger.load('/Users/rohanraj/Documents/Master/CaseStudy2/code/resources/taggers/netag/best-model.pt')\n",
    "\n",
    "df_ner = pd.DataFrame()\n",
    "\n",
    "r, c = df2.shape\n",
    "for row_no in range(r):\n",
    "    sentence = Sentence(df2['alt_title'][row_no])\n",
    "    model.predict(sentence)\n",
    "    sentence_ner = sentence.to_tagged_string()\n",
    "    temp_df = extract_ner(sentence_ner,row_no)\n",
    "    df_ner = df_ner.append(temp_df,ignore_index=True)  \n",
    "# predict tags and print\n",
    "#print(sentence.to_tagged_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>उस</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>समय</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>सुन्दर</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'सब</td>\n",
       "      <td>B-LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ओर</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence      word         ner\n",
       "0         0       उस            o\n",
       "1         0      समय            o\n",
       "2         0   सुन्दर     B-PERSON\n",
       "3         0      'सब   B-LOCATION\n",
       "4         0       ओर     B-PERSON"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ner.to_csv('../data/ner_tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ner = pd.read_csv('../data/ner_tag.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>उस</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>समय</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>सुन्दर</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'सब</td>\n",
       "      <td>B-LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ओर</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence      word         ner\n",
       "0         0       उस            o\n",
       "1         0      समय            o\n",
       "2         0   सुन्दर     B-PERSON\n",
       "3         0      'सब   B-LOCATION\n",
       "4         0       ओर     B-PERSON"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column Age has value 30\n",
    "df_ner_imp = df_ner[ df_ner['ner'].str.endswith('PERSON') | df_ner['ner'].str.endswith('LOCATION') ]\n",
    "# Delete these row indexes from dataFrame\n",
    "#df_ner.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>सुन्दर</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'सब</td>\n",
       "      <td>B-LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ओर</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>श्वेत</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>मेघ</td>\n",
       "      <td>B-PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence      word         ner\n",
       "2         0   सुन्दर     B-PERSON\n",
       "3         0      'सब   B-LOCATION\n",
       "4         0       ओर     B-PERSON\n",
       "8         0    श्वेत     B-PERSON\n",
       "9         0      मेघ     B-PERSON"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ner_imp.to_csv('../data/ner_tag_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ner.to_csv('../data/ner_tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standford nlp is being used for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatized_text = []\n",
    "    for line in tqdm(text):\n",
    "        if line not in [\"\",\" \"] :\n",
    "            doc = nlp(line)\n",
    "            for sent in doc.sentences:\n",
    "                for wrd in sent.words:\n",
    "                    #extract text and lemma\n",
    "                    lemmatized_text.append(wrd.lemma)\n",
    "    return lemmatized_text\n",
    "\n",
    "def remove_stopwords(word_tokenized,stop_words):\n",
    "    return [word for word in word_tokenized if word not in stop_words]\n",
    "\n",
    "def custom_remove_garbage(original_words_list,list_of_garbage_words):\n",
    "    tmp_list = [word for word in original_words_list if word not in list_of_garbage_words] # garbage list\n",
    "    tmp_list = [word for word in tmp_list if len(re.findall(\"\\d+\",word))==0] # english numbers\n",
    "    tmp_list = [word for word in tmp_list if len(re.findall(\"[a-zA-Z]+\",word))==0] # english alphabets\n",
    "    return tmp_list\n",
    "\n",
    "def Diff(li1, li2): \n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2] \n",
    "    return li_dif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Meddling after prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modelling(text_sentence,stop_words):\n",
    "    df = pd.DataFrame()\n",
    "    startflag = 0\n",
    "    endflag = 25\n",
    "    for text in range(int(len(text_sentence)/endflag)):\n",
    "        \n",
    "        #Clean text after lemmatization\n",
    "        lemmatized = lemmatization(text_sentence[startflag:endflag])\n",
    "        clean_text = remove_stopwords(lemmatized,stop_words)\n",
    "        #len(clean_text),len(lemmatized) #281,612\n",
    "        \n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in clean_text]\n",
    "        #print(stripped[:25])\n",
    "        #print(len(clean_text),len(stripped)) #281\n",
    "\n",
    "        resultant = Diff(clean_text,stripped)\n",
    "        #len(set(resultant)) #19\n",
    "\n",
    "        final_text = custom_remove_garbage(stripped,resultant)\n",
    "        #len(final_text) #265\n",
    "        \n",
    "        # Create Dictionary\n",
    "        id2word = corpora.Dictionary([final_text])\n",
    "\n",
    "        # Create Corpus\n",
    "        texts = final_text\n",
    "\n",
    "        # Term Document Frequency\n",
    "        corpus = [id2word.doc2bow(texts)] \n",
    "        \n",
    "        # Build LDA model\n",
    "\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=1, \n",
    "                                           random_state=100,\n",
    "                                           update_every=10,\n",
    "                                           chunksize=100,\n",
    "                                           passes=20,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        #pprint(lda_model.print_topics())\n",
    "        temp_file = datapath(\"model\")\n",
    "        lda_model.save(temp_file)\n",
    "        lda = gensim.models.ldamodel.LdaModel.load(temp_file)\n",
    "        lda.update(corpus)\n",
    "        lda.save('model')\n",
    "        temp_df = pd.DataFrame(lda.print_topics())\n",
    "        df = df.append(temp_df,ignore_index=True) \n",
    "        startflag +=25\n",
    "        endflag +=25\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.72it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.74it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.36it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.54it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.24it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.88it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.72it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.73it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.24it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.04it/s]\n",
      "100%|██████████| 25/25 [00:03<00:00,  8.10it/s]\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.65it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.76it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.40it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.87it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.62it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.13it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.48it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.78it/s]\n",
      "100%|██████████| 25/25 [00:03<00:00,  8.02it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.87it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.77it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.32it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.38it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.70it/s]\n"
     ]
    }
   ],
   "source": [
    "df4 = topic_modelling(text_sentence,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.025*\"कह\" + 0.019*\"वाक्य\" + 0.013*\"विभीषण\" + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018*\"वाक्य\" + 0.011*\"भाई\" + 0.011*\"विभीषण\" +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024*\"कह\" + 0.024*\"सब\" + 0.021*\"राम\" + 0.017*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.025*\"राम\" + 0.017*\"समुद्र\" + 0.014*\"रावण\" + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029*\"सेना\" + 0.024*\"सारण\" + 0.021*\"कह\" + 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1\n",
       "21  0  0.025*\"कह\" + 0.019*\"वाक्य\" + 0.013*\"विभीषण\" + ...\n",
       "22  0  0.018*\"वाक्य\" + 0.011*\"भाई\" + 0.011*\"विभीषण\" +...\n",
       "23  0  0.024*\"कह\" + 0.024*\"सब\" + 0.021*\"राम\" + 0.017*...\n",
       "24  0  0.025*\"राम\" + 0.017*\"समुद्र\" + 0.014*\"रावण\" + ...\n",
       "25  0  0.029*\"सेना\" + 0.024*\"सारण\" + 0.021*\"कह\" + 0.0..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4.to_csv('combined_model_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = datapath(\"model\")\n",
    "lda = gensim.models.ldamodel.LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4 =pd.read_csv('../data/combined_model_topic.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017*\"भवन\" + 0.015*\"सीता\" + 0.012*\"राक्षस\" + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.015*\"हनुमान\" + 0.013*\"युक्त\" + 0.013*\"सब\" + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027*\"राम\" + 0.016*\"सीता\" + 0.013*\"वानर\" + 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027*\"रावण\" + 0.015*\"सीता\" + 0.011*\"भूषण\" + 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014*\"पा\" + 0.011*\"सीता\" + 0.009*\"वचन\" + 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  0.017*\"भवन\" + 0.015*\"सीता\" + 0.012*\"राक्षस\" + ...\n",
       "1  0  0.015*\"हनुमान\" + 0.013*\"युक्त\" + 0.013*\"सब\" + ...\n",
       "2  0  0.027*\"राम\" + 0.016*\"सीता\" + 0.013*\"वानर\" + 0....\n",
       "3  0  0.027*\"रावण\" + 0.015*\"सीता\" + 0.011*\"भूषण\" + 0...\n",
       "4  0  0.014*\"पा\" + 0.011*\"सीता\" + 0.009*\"वचन\" + 0.00..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-84ee7c7bf2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "df4['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2, step=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '*',\n",
       " '\"',\n",
       " '\"']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[!@#$%^&*(),.?\":{}|<>]',df4[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'भवन  सीता  राक्षस  सुन्दर  भया  रावण  वानर  सक्ती  मा  स्त्री'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[!@#$%^&*(),.?\"+:{}|<>0-9]', '', df4[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_topic(df):\n",
    "    parsed_text = {'top_topic':[]}\n",
    "    \n",
    "    for ind in df.index:\n",
    "        parsed_text['top_topic'].append(re.sub('[!@#$%^&*(),.?\"+:{}|<>0-9]', '', df[1][ind]))\n",
    "    return pd.DataFrame(parsed_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df= process_topic(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'सेना  सारण  कह  राम  वानर  राक्षस  गुप्तचर  बोल  शुक  विभीषण'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df['top_topic'][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv('combined_model_topic_top_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
